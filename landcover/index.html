<style type="text/css">
	@import url("style.css")
</style>

<body>
	<img src="images/global_lulc_final_v1.jpg"  alt="">
	<h1>
		Global Land Cover Mapping
	</h1>

	<h3>
		<a href="https://igarss2021.com/view_paper.php?PaperNum=3500" target="_blank">Global land use / land cover with Sentinel 2 and deep learning</a><br />
		<a href="https://livingatlas.arcgis.com/landcover" target="_blank">ESRI Land Cover</a><br />
		<a href="https://www.arcgis.com/apps/instant/media/index.html?appid=fc92d38533d440078f17678ebc20e8e2" target="_blank">Download the data</a><br />
		<a href="https://storymaps.arcgis.com/stories/486cd2ae2016454f951c97f802f125b3" target="_blank">A new land cover map of the world</a><br />
		<a href="https://www.bbc.com/news/science-environment-57615408" target="_blank">'Eyes of a machine': How to classify Planet Earth</a><br />
		June 2021<br /><br />
		Krishna Karra<br />
		With <a href="https://impactobservatory.com" target="_blank">Impact Observatory</a><br /><br />
	</h3>

	<p>
	Land cover maps are foundational geospatial data products for understanding the state of the environment and how it's changing. Typically, these maps (like <a href="https://www.mrlc.gov" target="_blank">NLCD</a> made by <a href="https://www.usgs.gov" target="_blank">USGS</a>) take years to create, require manual/expert tweaking, and are limited in geographic scope. At Impact Observatory, we set out to create a global 2020 land cover map, with 10 discrete classes, from Sentinel-2 imagery, at 10-meter resolution. The map was developed with <a href="https://livingatlas.arcgis.com/landcover" target="_blank">Esri</a> and in partnership with <a href="https://www.microsoft.com/en-us/ai/ai-for-earth" target="_blank"> Microsoft AI for Earth</a>. The map is an open dataset and freely available with a CC-by license, and you can download it <a href=https://www.arcgis.com/apps/instant/media/index.html?appid=fc92d38533d440078f17678ebc20e8e2" target="_blank">here</a>.
	</p>

	<p>
	I led the design and development of a deep learning-based segmentation model that takes an input 6-band (red, green, blue, nir, swir1, swir2) Sentinel-2 image at a single point in time, and outputs a 10-class land cover classification. A <a href="https://arxiv.org/abs/1505.04597" target="_blank">UNet</a> model was trained from scratch on a massive global dataset consisting of over 5 billion hand-labeled pixels. A weighted categorical <a href="https://en.wikipedia.org/wiki/Cross_entropy" target="_blank">cross entropy</a> loss function was used to account for pixel-wise class imbalance, weighting under-represented classes such as grass higher than over-represented classes such as forest.
	</p>

	<p>
	While instantaneous land cover classififications on single scenes can be useful for some applications, we chose to incorporate many scenes across 2020 to create a land cover map that is representative of the whole year. This approach minimizes issues that inevitably arise due to cloud cover variability and data coverage gaps. More scenes are used in very cloudy parts of the world compared to cloud-free areas. To take a stack of imagery over a region and convert it into a single map, the segmentation model is run over each scene in the stack. Then, a <a href="https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.weighted_mode.html" target="_blank">weighted mode</a> is computed across the predictions, incorporating the probability of each classification along with a custom weight per class. The custom class weight can be thought of as a seasonal adjustment, which emphasizes ephemeral classes that may only occur a few times per year such as grass, and de-emphasizes classes that are transient such as snow/ice.
	</p>

	<p>
	For more details on this work, check out our paper (awaiting publication) and presentation at <a href="https://igarss2021.com/view_paper.php?PaperNum=3500" target="_blank">IGARSS 2021</a>.
	</p>
</body>
